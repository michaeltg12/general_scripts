{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Exploration and Results for D080428.4 --\n",
    "## --Threshhold Rainrate -- \n",
    "Author: Michael Giansiracusa  \n",
    "Email: <giansiracumt@ornl.gov>  \n",
    "DQR info: [D080428.4](http://www.archive.arm.gov/ArchiveServices/DQRService?dqrid=D080428.4) twp/met/C2  \n",
    "DQR submitted by: Michael T. Ritsche, <mritsche@anl.gov>  \n",
    "Evaluation date: 19 Sept 2018\n",
    "\n",
    "This scirpt was written for a group of DQRs which contained the following desription.\n",
    "### Description\n",
    "The ORG data is collected via analog signal and not digital. Therefore, we continuously collect data even when no rain is occurring. We also capture small events such as leaves, large bugs, dust, etc blowing through the measurement path. Because this discrete event occurs quickly the value is usually captured for 1 or 2 seconds. This value is then averaged to the minute producing rainrate on the order of .009 mm/hr or less. \n",
    "\n",
    "These values are not indicative of rain and should be removed from the record or summing over long periods can bias the climate record. We will reprocess the data to remove these small values.\n",
    "### Data Info\n",
    "Raw data staged from hpss: /f1/arm/raw/twpmetC3.00 and from amber: /data/archive/twp/twpmetC3.00/ (amber brd = 192.148.97.127). Processed netCDF data staged from amber: /data/archive/twp/twpmetC3.b1/.\n",
    "\n",
    "### Conclusions...\n",
    "This task needs more specific guidelines for how to proceed. Since the mean and standard deviation are calculated in the logger it may be impossible to make these changes so that they are meaningul and correct. The max is never below the threshold so we can't ever simply make all values 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data in the following folder will be inspected.\n",
      "\t/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1\n"
     ]
    }
   ],
   "source": [
    "## Set input directory for netCDF file inspection\n",
    "'''\n",
    "Directory should not contain any data that should not be inspected.\n",
    "Any folders in the directory should be hidden and begin with a period.\n",
    "'''\n",
    "input_dir = \"/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1\"\n",
    "print(\"All data in the following folder will be inspected.\\n\\t{}\".format(input_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20040701.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20040702.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20040703.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20040704.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20040705.000000.cdf\n",
      "......\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20041227.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20041228.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20041229.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20041230.000000.cdf\n",
      "/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20041231.000000.cdf\n"
     ]
    }
   ],
   "source": [
    "files = glob(os.path.join(input_dir, \"twpmetC3.b1.*\"))\n",
    "files.sort()\n",
    "if files:\n",
    "    for f in files[0:5]:\n",
    "        print(f)\n",
    "    print(\"......\")\n",
    "    for f in files[-5:]:\n",
    "        print(f)\n",
    "else:\n",
    "    print(\"No files returned from input search:\\n\\t{}\".format(os.path.join(input_dir, \"twpmetC3.b1.*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Checking variable names --\n",
    "The following is a exploration of the variables in the netCDF files for this reprocessing job.\n",
    "\n",
    ">I am attempting to find the names of the variables that contain rain data and are not quality control variables. \n",
    "\n",
    ">I'll do this by checking a equidistant selection of files, within which I am checking each variable name for the substring 'precip' and 'rain'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precip and rain variables for file - /data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1/twpmetC3.b1.20040701.000000.cdf\n",
      "\torg_precip_rate_mean\n",
      "\torg_precip_rate_std\n",
      "\torg_precip_rate_max\n",
      "\torg_precip_rate_min\n",
      "\ttbrg_precip_total\n",
      "\ttbrg_precip_count\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    if i % 200 == 0:\n",
    "        test_dataset = Dataset(files[0])\n",
    "        #print(\"All variables for file - {}\".format(files[0]))\n",
    "        #print(\"\\t\" + str(test_dataset.variables.keys()))\n",
    "        print(\"\\nPrecip and rain variables for file - {}\".format(files[0]))\n",
    "        for key in test_dataset.variables.keys():\n",
    "            if (\"precip\" in key or \"rain\" in key) and \"qc_\" not in key:\n",
    "                    print(\"\\t\" + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Checking variable values --\n",
    "An exploration of variables identified for values below threshhold.\n",
    "> I'll be checking each variable identified in the previous cell for values that are equal to or below the threshhold mentioned in the dqr report (0.009). \n",
    "\n",
    "> I have removed the standard deviation variable from this selection. Although it has values below the threshhold, it is not representative of anomolies in the measurement as a result of quick, discrete events such as leaves, large bugs, dust, etc blowing through the measurement path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold_value = 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    value_dict, value_list = {}, []\n",
    "    print(f)\n",
    "    dataset = Dataset(f)\n",
    "    for key in dataset.variables.keys():\n",
    "        if \"precip_rate_mean\" in key and (\"qc_\" not in key and \"_std\" not in key):\n",
    "            print(\"\\t\" + key)\n",
    "            for value in dataset.variables[key][:]:\n",
    "                if value > 0 and value < 0.01:\n",
    "                    print(\"\\t\\t\" + str(value))\n",
    "                    if value <= threshhold_value:\n",
    "                        print(\"\\t\\tmodifying \" + str(value))\n",
    "                        value_list.append(value)\n",
    "            if value_list:\n",
    "                value_dict[key] = value_list\n",
    "    if value_dict:\n",
    "        print(f)\n",
    "        for key in value_dict.keys():\n",
    "            print(\"\\t\" + key)\n",
    "            for value in value_dict[key]:\n",
    "                print(\"\\t\\t\" + str(value))\n",
    "    else:\n",
    "        print(\"No values below {} in file - {}\".format(threshhold_value, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Conclusions --\n",
    "> After running the above cells, it is my conclusion that there are no values in the variables that represent rain rate, for any file in the time range identified in the dqr which are below the threshhold. Because of this, there is nothing to change for this job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Confirming Results --\n",
    "Evaluating raw data to confirm results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data in the following folder will be modified.\n",
      "\t/data/project/0021718_1509993009/D080428.3/collection/twp/twpmetC3.00/.from_local_tars/.raw\n"
     ]
    }
   ],
   "source": [
    "## Set input directory for raw file inspection\n",
    "'''\n",
    "Directory should not contain any data that should not be inspected.\n",
    "Any folders in the directory should be hidden and begin with a period.\n",
    "'''\n",
    "raw_input_dir = \"/data/project/0021718_1509993009/D080428.3/collection/twp/twpmetC3.00/.from_local_tars/.raw\"\n",
    "# there was also a .orig and .bad directory that contained files that were in the tar bundles with those substrings in the file names\n",
    "\n",
    "print(\"All data in the following folder will be modified.\\n\\t{}\".format(raw_input_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Data Dictionaries --\n",
    "This evaluation will use data dictionaries in json format to map raw data columns to variable in the corresponding netCDF files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permanent data dictionaries in $REPROC_HOME/working_data_dictionaries folder on adc machines\n",
    "# *** used gen_dict_gen.py in ADC toolbox bin folder to map columns ***\n",
    "data_dict_1 = json.load(open(\"twpmetC3.00.20040701.unknown.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org_precip_rate_mean - {'column': 4, 'data_type': 'float32', 'dimensions': 'time', 'notes': '', 'attributes': {'long_name': 'ORG precipitation rate mean', 'missing_value': -9999, 'units': 'mm/hr', 'valid_max': 500, 'valid_min': 0}}\n"
     ]
    }
   ],
   "source": [
    "for key in data_dict_1[\"data\"].keys():\n",
    "    if \"precip\" in key:\n",
    "        print(\"{} - {}\".format(key, data_dict_1[\"data\"][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: /data/project/0021718_1509993009/D080428.3/collection/twp/twpmetC3.00/.from_local_tars/.raw\n",
      "\tFirst 5\n",
      "twpmetC3.00.20040701.000000.raw.20040701000000.dat\n",
      "twpmetC3.00.20040701.010000.raw.20040701010000.dat\n",
      "twpmetC3.00.20040701.020000.raw.20040701020000.dat\n",
      "twpmetC3.00.20040701.030000.raw.20040701030000.dat\n",
      "twpmetC3.00.20040701.040000.raw.20040701040000.dat\n",
      "..........................................\n",
      "\tLast 5\n",
      "twpmetC3.00.20100630.190000.raw.20100630190000.dat\n",
      "twpmetC3.00.20100630.200000.raw.20100630200000.dat\n",
      "twpmetC3.00.20100630.210000.raw.20100630210000.dat\n",
      "twpmetC3.00.20100630.220000.raw.20100630220000.dat\n",
      "twpmetC3.00.20100630.230000.raw.20100630230000.dat\n"
     ]
    }
   ],
   "source": [
    "raw_files = glob(os.path.join(raw_input_dir, \"twpmetC3.00.*\"))\n",
    "raw_files.sort()\n",
    "print(f\"Files in directory: {raw_input_dir}\")\n",
    "if raw_files:\n",
    "    num_rows = 5\n",
    "    print(f\"\\tFirst {str(num_rows)}\")\n",
    "    for f in raw_files[0:num_rows]:\n",
    "        print(os.path.basename(f))\n",
    "    print(\".\"*42)\n",
    "    print(f\"\\tLast {str(num_rows)}\")\n",
    "    for f in raw_files[-num_rows:]:\n",
    "        print(os.path.basename(f))\n",
    "else:\n",
    "    print(\"No files returned from input search:\\n\\t{}\".format(os.path.join(input_dir, \"twpmetC3.b1.*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set threshhold value \n",
    "raw_threshhold_value = 0.009\n",
    "\n",
    "# Manually set column to threshhold but this could be auto set from output of earlier cell\n",
    "\"\"\"\n",
    "for smet files up to smet20040517210300_20040517220201.C3\n",
    "    3 = mean, 4 = std, 5 = max, 6 = min\n",
    "for .dat files from 20040519055900.dat forward\n",
    "    4 = mean, 5 = std, 6 = max, 7 = min\n",
    "\"\"\"\n",
    "eval_column = [4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Inspecting Raw Data -- \n",
    "Below we inspect the raw data for values that are below the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in raw_files:\n",
    "    value_dict, value_list = {}, []\n",
    "    #print(f)\n",
    "    with open(f) as open_raw_file:\n",
    "        csv_file_reader = csv.reader(open_raw_file)\n",
    "        for line in csv_file_reader:\n",
    "            #print(\"\\tcolumn = {}\".format(eval_column))\n",
    "            value = eval(line[3])\n",
    "            if line[0] == \"1\" and (value > 0 and value < raw_threshhold_value):\n",
    "                value_list.append(value)\n",
    "                #print(\"\\t\\t\" + value)\n",
    "        if value_list:\n",
    "            key = \"org_rate_precip_mean\".format(5)\n",
    "            value_dict[key] = value_list\n",
    "    if value_dict:\n",
    "        print(os.path.basename(f))\n",
    "        for key in value_dict.keys():\n",
    "            print(\"\\t\" + key)\n",
    "            for value in value_dict[key]:\n",
    "                print(\"\\t\\t\" + str(value))\n",
    "    else:\n",
    "        #print(\"No values below {} in file - {}\".format(raw_threshhold_value, os.path.basename(f)))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Revised Conclusion --\n",
    "Identified values in raw files that are below threshhold value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Threshholding Raw Files --\n",
    "Threshhold the values identified in the previous cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/data/project/0021718_1509993009/D080428.3/collection/twp/twpmetC3.00\"\n",
    "for f in raw_files:\n",
    "#     print(os.path.basename(f))\n",
    "    modified_lines = []\n",
    "    with open(f) as open_raw_file:\n",
    "        csv_file_reader = csv.reader(open_raw_file)\n",
    "        for i, line in enumerate(csv_file_reader):\n",
    "            #print(\"\\tcolumn = {}\".format(eval_column))\n",
    "            max_value = eval(line[eval_column[2]])\n",
    "            if line[0] == \"1\":\n",
    "                if max_value > 0 and max_value < raw_threshhold_value:\n",
    "                    line[eval_column[0]] = \"0\"\n",
    "                    line[eval_column[1]] = \"0\"\n",
    "                    line[eval_column[2]] = \"0\"\n",
    "                    line[eval_column[3]] = \"0\"\n",
    "                    print(\"{} : {},value {},{},{},{} --> 0\".format(os.path.basename(f), str(line[1:4]), mean_value, sd_value, max_value, min_value))\n",
    "            modified_lines.append(line)\n",
    "    output_file = os.path.join(output_directory, os.path.basename(f))\n",
    "    with open(output_file, 'w') as open_output_file:\n",
    "        csv_file_writer = csv.writer(open_output_file)\n",
    "        csv_file_writer.writerows(modified_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Post Modification --\n",
    "After the raw files are modified I ran the `strip_arm_names` script to remove the arm name from the file before ingest.\n",
    "The effect of which removed the datastream, date, and raw substrings from the file name, turning a file like twpmetC3.00.20040723.020000.raw.20040723020000.dat into 20040723020000.dat and then the files are ingested using the command `met_ingest -d twp -f C3 -DR` so that the cdf files can be compared. NetCDF files compared using script below for small subset of the data and using ncreview for the full data set. Durring the ingest, the -F flag was used to bypass overlapping time records and the resulting ncreview is at the following link: https://engineering.arm.gov/ncreview/?/data/project/0021718_1509993009/post_processing/D080428.3/ncr_twpmetC3.b1.2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Checking netCDF Files --\n",
    "I'll be running through the variables I think changed in the netCDF files and checking them for the modifications. I used a DiffMerge to compare the raw files and verified that they changed but when I run ncreview on the netCDF files, it shows no change. My theory is that the change is so small that ncreview isn't showing it but it does exist in the netCDF files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from netCDF4 import Dataset\n",
    "from glob import glob\n",
    "\n",
    "orig_dir = \"/data/archive/twp/twpmetC3.b1\"\n",
    "mod_dir = \"/data/project/0021718_1509993009/D080428.3/datastream/twp/twpmetC3.b1\"\n",
    "'''This part is just a conjunction of 3 things. \n",
    "First, use os to create a generalized path name,\n",
    "second, use glob to get a list of regex matches in that path, \n",
    "third, strip the path and just get the base filename.'''\n",
    "fnames = [os.path.basename(f) for f in glob(os.path.join(mod_dir, \"*.cdf\"))]\n",
    "\n",
    "fnames.sort()\n",
    "\n",
    "for fname in fnames:\n",
    "    print(f\"Inspecting - {fname}\")\n",
    "    do = Dataset(os.path.join(orig_dir, fname))\n",
    "    dm = Dataset(os.path.join(mod_dir, fname))\n",
    "\n",
    "    \"\"\" Get the variables in the modified file that have the substing precip in them and don't have \n",
    "    the substrings qc or std. This effectively gets all rain variables that aren't quality control\n",
    "    variables and aren't standard deviation ones. \"\"\"\n",
    "    vars = [v for v in dm.variables.keys() if (\"precip\" in v and \"qc\" not in v and \"std\" not in v)]\n",
    "\n",
    "    for var in vars:\n",
    "        print(f\"\\t...{var}\")\n",
    "        \"\"\" Zip the lists together. Both will get truncated to the size of the smaller one. :-(\"\"\"\n",
    "        for x, y in zip(do.variables[var][:], dm.variables[var][:]):\n",
    "#                 print(x, \"--\", y)\n",
    "            # extra prints for alternative comparison functionality\n",
    "            if x > 0 or y > 0:\n",
    "                if x != y:\n",
    "                    print(\"\\t\\t{} != {}\".format(x, y), end=\"\")\n",
    "                else:\n",
    "#                         print(\"\\t{} == {}\".format(x, y))\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Visual comparison --\n",
    "Comparison of raw files done on local machine using DiffMerge.  \n",
    "![raw files](files/raw_comparison.png)  \n",
    "Snapshot of output from last cell which compares the cdf files  \n",
    "![cdf files](files/cdf_comparison.png)  \n",
    "From the infomation above I have concluded that (for at least some of the files but I suspect all of them) the cdf files were thresholded before or durring ingest. I checked hpss and these cdf files are all v0 so they haven't been rearchived. This means that changing the raw files will have no effect on the cdf files. Therefore, I'll change the raw files, double check that the cdf files didn't change then rearchive only the changed files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
